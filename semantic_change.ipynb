{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('popular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from subprocess import call\n",
    "import re\n",
    "import lxml.html\n",
    "import pymorphy2\n",
    "m = pymorphy2.MorphAnalyzer()\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "import json\n",
    "import logging\n",
    "\n",
    "stopWords = set(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_in_json(path, data):\n",
    "    f = open(path, 'w', encoding = 'utf-8')\n",
    "    json.dump(data, f, indent = 2, ensure_ascii = False)\n",
    "    f.close()\n",
    "    \n",
    "def read_from_json(path):\n",
    "    with open(path, encoding = 'utf-8') as json_file:  \n",
    "        data = json.load(json_file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getText(file):\n",
    "    f = open(file, 'rb')\n",
    "    html = f.read()\n",
    "    f.close()\n",
    "    tree = lxml.html.fromstring(html)\n",
    "    try:\n",
    "        words = tree.xpath('.//meta[@name=\"words\"]')[0].get('content')\n",
    "    except:\n",
    "        words = '-'\n",
    "    ps = tree.xpath('.//p[not(@*)]/text()')\n",
    "    text = []\n",
    "    for sent in ps:\n",
    "        sent = sent.replace('/ха0',' ')\n",
    "        text.append(sent)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_date(date):\n",
    "    if re.match('[0-9]{4}', date):            \n",
    "        if re.match('[0-9]{4}\\.[0-9]{2}',date):\n",
    "            date = date[:4]\n",
    "        elif re.match('[0-9]{4}',date[-4:]):\n",
    "            date = date[-4:]            \n",
    "        else:\n",
    "            return '0'\n",
    "        return date\n",
    "    elif re.match('[0-9]{2}\\.[0-9]{2}\\.[0-9]{4}',date):\n",
    "        date = date[-4:]\n",
    "        return date\n",
    "    else:\n",
    "        return '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def walk_corpora():\n",
    "    f = open('source.csv', 'r', encoding = 'utf-8')\n",
    "    metta = f.readlines()\n",
    "    metta = metta[1:]\n",
    "    for line in metta:\n",
    "        line = line.split(';')\n",
    "        path = line[0] \n",
    "        for i in [5,6,7,8,9]:\n",
    "            date = check_date(line[i])\n",
    "            if date == '0':\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "        if date == '0':\n",
    "            print('bad date ' + path)\n",
    "        if int(date) < 1998:\n",
    "            continue\n",
    "        words = line[-1]        \n",
    "        json_path = date + '_' + path.replace('/','_') + '.json'\n",
    "        if os.path.isfile(json_path):\n",
    "            #print('already have '+json_path)\n",
    "            continue\n",
    "        print('reading ' + path)        \n",
    "        if '.xhtml' not in path:\n",
    "            htm_path = path + '.xhtml'\n",
    "        else:\n",
    "            htm_path = path\n",
    "        \n",
    "        text = getText(htm_path)\n",
    "        filt_text = []\n",
    "        for sent in text:\n",
    "            s = []\n",
    "            sent = sent.split()\n",
    "            for word in sent:\n",
    "                if word in stopWords:\n",
    "                    continue\n",
    "                word = word.strip('[](),.;:-_+=/*\"«»!?<>')\n",
    "                lemma = m.parse(word)[0].normal_form                \n",
    "                s.append(lemma)\n",
    "            if len(s) == 1:\n",
    "                continue\n",
    "            filt_text.append(s)\n",
    "        \n",
    "        write_in_json('texts/'+json_path, filt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_corpora()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts_1927 = []\n",
    "texts_1937 = []\n",
    "texts_1947 = []\n",
    "texts_1957 = []\n",
    "texts_1967 = []\n",
    "texts_1977 = []\n",
    "texts_1987 = []\n",
    "texts_1997 = []\n",
    "texts_2007 = []\n",
    "texts_2017 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relevant_period(year, text):\n",
    "    if year < 1927:            \n",
    "        for sent in text:\n",
    "            texts_1927.append(sent)\n",
    "    elif year < 1937:\n",
    "        for sent in text:\n",
    "            texts_1937.append(sent)\n",
    "    elif year < 1947:\n",
    "        for sent in text:\n",
    "            texts_1947.append(sent)\n",
    "    elif year < 1957:\n",
    "        for sent in text:\n",
    "            texts_1957.append(sent)\n",
    "    elif year < 1967:\n",
    "        for sent in text:\n",
    "            texts_1967.append(sent)\n",
    "    elif year < 1977:\n",
    "        for sent in text:\n",
    "            texts_1977.append(sent)\n",
    "    elif year < 1987:\n",
    "        for sent in text:\n",
    "            texts_1987.append(sent)\n",
    "    elif year < 1997:\n",
    "        for sent in text:\n",
    "            texts_1997.append(sent)\n",
    "    elif year < 2007:\n",
    "        for sent in text:\n",
    "            texts_2007.append(sent)\n",
    "    elif year < 2017:\n",
    "        for sent in text:\n",
    "            texts_2017.append(sent)\n",
    "        \n",
    "\n",
    "def load_texts(period):\n",
    "    dirs = os.walk('texts')\n",
    "    for dirr in dirs:    \n",
    "        path = dirr[0] + '/'\n",
    "        files = dirr[2]\n",
    "        for file in files:            \n",
    "            year = int(file[:4])\n",
    "            if (year < period) and (year > period - 11) and file.endswith('json'):\n",
    "                print(year)\n",
    "                text = read_from_json(path + file)\n",
    "                relevant_period(year, text)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_texts(2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(texts_2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0 = Word2Vec(texts_1927, min_count=10, size=300, window = 3, workers = 4)\n",
    "model_0.save('model_1927')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "model_0.train(texts_1937, total_examples=model_0.corpus_count, epochs=model_0.iter)\n",
    "model_0.save('model_1937')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "model_0.train(texts_1947, total_examples=model_0.corpus_count, epochs=model_0.iter)\n",
    "model_0.save('model_1947')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "model_0.train(texts_1957, total_examples=model_0.corpus_count, epochs=model_0.iter)\n",
    "model_0.save('model_1957')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "model_0.train(texts_1967, total_examples=model_0.corpus_count, epochs=model_0.iter)\n",
    "model_0.save('model_1967')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "model_0.train(texts_1977, total_examples=model_0.corpus_count, epochs=model_0.iter)\n",
    "model_0.save('model_1977')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "model_0.train(texts_1987, total_examples=model_0.corpus_count, epochs=model_0.iter)\n",
    "model_0.save('model_1987')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "model_0.train(texts_1997, total_examples=model_0.corpus_count, epochs=model_0.iter)\n",
    "model_0.save('model_1997')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "model_0.train(texts_2007, total_examples=model_0.corpus_count, epochs=model_0.iter)\n",
    "model_0.save('model_2007')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0.train(texts_2017, total_examples=model_0.corpus_count, epochs=model_0.iter)\n",
    "model_0.save('model_2017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0 = Word2Vec.load('model_1927')\n",
    "model_1 = Word2Vec.load('model_1937')\n",
    "model_2 = Word2Vec.load('model_1947')\n",
    "model_3 = Word2Vec.load('model_1957')\n",
    "model_4 = Word2Vec.load('model_1967')\n",
    "model_5 = Word2Vec.load('model_1977')\n",
    "model_6 = Word2Vec.load('model_1987')\n",
    "model_7 = Word2Vec.load('model_1997')\n",
    "model_8 = Word2Vec.load('model_2007')\n",
    "model_9 = Word2Vec.load('model_2017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "import scipy\n",
    "\n",
    "models = [model_0, model_1, model_2, model_3, model_4, model_5, model_6, model_7, model_8, model_9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(w):\n",
    "    try:\n",
    "        w_27 = model_0[w]\n",
    "        w_17 = model_9[w]\n",
    "        dist = spatial.distance.cosine(w_27, w_17)\n",
    "        return dist\n",
    "    except:\n",
    "        return ' -'\n",
    "    \n",
    "\n",
    "words = ['мышь', 'мышка', 'развод', 'подписчик', 'крыша', 'корпорация', 'стрелка', 'голубой', 'ударник', 'товарищ', 'винчестер', 'дурь', 'левый', 'раздача', 'убитый', 'климат', 'наезд', 'нелицеприятный', 'страница', 'карта', 'фрукт', 'талон', 'гнездо', 'канал', 'узел', 'базар', 'буханка', 'сообщение', 'жесть', 'откровенный', 'корочка', 'хлопья', 'гуманист', 'тюфяк', 'лагерь', 'трико', 'мерин', 'платформа', 'парусиновый', 'шляпка', 'классный', 'пакет']\n",
    "for w in words:\n",
    "    print(w)\n",
    "    print(cos_sim(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('kendall.tsv', 'a', encoding = 'utf-8')\n",
    "f.write('word\\tchange\\t1927\\t1937\\t1947\\t1957\\t1967\\t1977\\t1987\\t1997\\t2007\\t2017')\n",
    "\n",
    "def kendall(syns_1, syns_2):\n",
    "    n = 0\n",
    "    rangs_1 = []\n",
    "    rangs_2 = []\n",
    "    dic = {}\n",
    "    for s in syns_1:\n",
    "        if s[0] in dic:\n",
    "            rangs_1.append(dic[s[0]])\n",
    "        else:\n",
    "            n += 1\n",
    "            dic[s[0]] = n\n",
    "            rangs_1.append(n)\n",
    "    for s in syns_2:\n",
    "        if s[0] in dic:\n",
    "            rangs_2.append(dic[s[0]])\n",
    "        else:\n",
    "            n += 1\n",
    "            dic[s[0]] = n\n",
    "            rangs_2.append(n)\n",
    "    return rangs_1, rangs_2\n",
    "\n",
    "def met1(m_1, m_2, w):    \n",
    "    syns_1 = m_1.most_similar(positive = w, topn = 50)\n",
    "    syns_2 = m_2.most_similar(positive = w, topn = 50)\n",
    "    rangs = kendall(syns_1, syns_2)\n",
    "    tau = scipy.stats.kendalltau(rangs[0], rangs[1])\n",
    "    if tau[1] < 0.1:\n",
    "        f.write(str(tau[0])+ '\\t')\n",
    "    else:\n",
    "        f.write('-'+ '\\t')\n",
    "\n",
    "def corr(w):    \n",
    "    f.write('\\n'+w + '\\t')\n",
    "    for i in range(9):\n",
    "        met1(models[i], models[i+1], w)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = open('words.txt', 'r', encoding = 'utf-8')\n",
    "words_test = ff.readlines()\n",
    "for word in words_test:\n",
    "    word = word.strip('\\n')\n",
    "    corr(word)\n",
    "f.close()\n",
    "ff.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('sov.tsv', 'a', encoding = 'utf-8')\n",
    "f.write('word\\t1937\\t1947\\t1957\\t1967\\t1977\\t1987\\t1997\\t2007\\t2017')\n",
    "\n",
    "def comm(syns_1, syns_2):\n",
    "    dic = []\n",
    "    for s in syns_1:\n",
    "        if s[0] not in dic:            \n",
    "            dic.append(s[0])\n",
    "    for s in syns_2:\n",
    "        if s[0] not in dic:            \n",
    "            dic.append(s[0])\n",
    "    return dic\n",
    "\n",
    "def met2(m_1, m_2, w):    \n",
    "    syns_1 = m_1.most_similar(positive = w, topn = 50)\n",
    "    syns_2 = m_2.most_similar(positive = w, topn = 50)\n",
    "    com = comm(syns_1, syns_2)\n",
    "    print('len of comm syns' + str(len(com)))\n",
    "    sov_1 = []\n",
    "    sov_2 = []\n",
    "    for s in com:\n",
    "        sov_1.append(m_1.similarity(w, s))\n",
    "        sov_2.append(m_2.similarity(w, s))\n",
    "    return spatial.distance.cosine(sov_1, sov_2)\n",
    "        \n",
    "def sec(w):    \n",
    "    f.write('\\n'+w)\n",
    "    for i in range(9):\n",
    "        print('model compare '+str(i))\n",
    "        cos = met2(models[i], models[i+1], w)\n",
    "        print('cos sim' + str(cos))\n",
    "        f.write('\\t' + str(cos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = open('words.txt', 'r', encoding = 'utf-8')\n",
    "words_test = ff.readlines()\n",
    "for word in words_test:\n",
    "    word = word.strip('\\n')\n",
    "    print(word)\n",
    "    sec(word)\n",
    "f.close()\n",
    "ff.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
